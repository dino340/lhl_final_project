{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a08205-65b5-43e7-aa13-3a189a38783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import vgg16, resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25956f6-923f-41b7-b398-b426f6c95b9c",
   "metadata": {},
   "source": [
    "transfer learning vgg16, resnet50, inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea1bf01-e5cc-4bfa-9673-78406582d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(weights = 'imagenet', # import VGG16 with pretrained weights\n",
    "                    include_top = False,   # don't include top layers to allow for transfer learning with my own\n",
    "                    input_shape= (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14e9272-19b0-49bf-abff-72dea97e3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: #set all layers in VGG16 to be trainable to allow for fine tuning\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ed0d33-02c0-4e04-98d8-af3a143fac2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View imported vgg16 model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7de3e84-05d3-4266-9460-879788ecf844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to add layers onto the imported vgg16 model\n",
    "\n",
    "def add_layers(bottom_model):\n",
    "    top_model = bottom_model.output\n",
    "    top_model = Flatten()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(256,activation='relu')(top_model)\n",
    "    top_model = Dense(3, activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df8d14e-a1f6-4bcd-923f-71d0d57216c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(50, activation='relu'),\n",
    "#     tf.keras.layers.Dense(3, activation='softmax')\n",
    "# ])\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc458290-a0e3-44a8-9e08-532c037120da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function and combine preimported model with added layers\n",
    "\n",
    "FC_Head = add_layers(model)\n",
    "\n",
    "model = Model(inputs = model.input, outputs = FC_Head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4bddc27-eab9-4258-8663-ecf4fa5b9eff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 27,692,355\n",
      "Trainable params: 12,977,667\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View entire model with added layers\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d688a3-a803-4b7c-b654-35797e8fa3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130046 images belonging to 3 classes.\n",
      "Found 37160 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define directory where training data is stored\n",
    "\n",
    "training_dir = 'split/train'\n",
    "\n",
    "# Set up data generator for training data, normalize and use image augmentation to suppliment images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# use data generator to flow from directory into model at 224x224 px as required by VGG16\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(training_dir,\n",
    "                                                    batch_size=32,\n",
    "                                                    target_size=(224,224))\n",
    "# Define directory where test data is stored\n",
    "test_dir = 'split/test'\n",
    "\n",
    "# Set up data generator for normalizing test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# use data generator to flow from directory into model at 224x224 px as required by VGG16\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  batch_size=32,\n",
    "                                                  target_size=(224,224))\n",
    "\n",
    "# Set up checkpoints to save best models based on validation loss during training\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=0,save_best_only=True,\n",
    "                             mode='auto')\n",
    "\n",
    "# Set up Early Stopping to stop training if no improvements are made within 10 epochs\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=10,\n",
    "                          restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735a444e-2295-4305-9fc3-700ba59a1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Adam optimizer using gradient clipping\n",
    "\n",
    "opt_adam = tf.keras.optimizers.Adam(clipnorm=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2861ef9c-c3c3-4049-b3dd-b2c08ecbca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model using set up optimizer and categorical loss and accuracy metrics\n",
    "\n",
    "model.compile(optimizer=opt_adam, loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f67d6-fc2c-4220-8ae1-fbe3816a6dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4064/4064 [==============================] - 3502s 860ms/step - loss: 0.1458 - categorical_accuracy: 0.9459 - val_loss: 0.0467 - val_categorical_accuracy: 0.9845\n",
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n",
      "Epoch 2/5\n",
      "4064/4064 [==============================] - 3477s 856ms/step - loss: 0.0834 - categorical_accuracy: 0.9704 - val_loss: 0.0252 - val_categorical_accuracy: 0.9910\n",
      "INFO:tensorflow:Assets written to: model-002.model\\assets\n",
      "Epoch 3/5\n",
      "4064/4064 [==============================] - 3298s 812ms/step - loss: 0.0697 - categorical_accuracy: 0.9758 - val_loss: 0.0222 - val_categorical_accuracy: 0.9931\n",
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n",
      "Epoch 4/5\n",
      "4064/4064 [==============================] - 3169s 780ms/step - loss: 0.0615 - categorical_accuracy: 0.9787 - val_loss: 0.0202 - val_categorical_accuracy: 0.9929\n",
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n",
      "Epoch 5/5\n",
      "2573/4064 [=================>............] - ETA: 16:50 - loss: 0.0582 - categorical_accuracy: 0.9803"
     ]
    }
   ],
   "source": [
    "# Run model fitting using training_generator, for 5 epochs, using test_generator for validation and using checkpoint and early stopping callbacks\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                             epochs=5,\n",
    "                             validation_data=test_generator,\n",
    "                             callbacks=[checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6b440-8d5b-4af9-a823-0b8e31dc4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize accuracy and save as png\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.savefig('model_acc.png', dpi=200, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663d8375-58dd-497e-80da-b17c1df2042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize loss and save as png\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper right')\n",
    "plt.savefig('model_loss.png', dpi=200, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f914f73-9f11-4007-9e25-b1ee65923868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('model-026.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa75ee-8a90-4279-949b-23ee3bbe6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory where validation data is stored\n",
    "val_dir = 'split/val'\n",
    "\n",
    "# Set up data generator for normalizing validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# use data generator to flow from directory into model at 224x224 px as required by VGG16\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                labels='inferred'\n",
    "                                                batch_size=32,\n",
    "                                                target_size=(224,224),\n",
    "                                                shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72244a-b713-439a-bd43-e660337b965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using validation generator\n",
    "model.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9245df-4d67-4764-bffa-a55cd6f8ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using validation generator\n",
    "Y_pred = model.predict(val_generator)\n",
    "# convert predictions into class labels\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efddcb-108a-4477-a2fc-781a96ddcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Run a confusion matrix based on predictions and expected labels\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_generator.classes, y_pred))\n",
    "\n",
    "# Run classification report on predictions and \n",
    "print('n/Classification Report')\n",
    "target_names = ['correctly_worn', 'incorrectly_worn', 'no_mask']\n",
    "print(classification_report(val_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcaff2-57f8-45c0-84da-ba35db1c76bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
